{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef main(_):\\n    \"\"\"High level pipeline.\\n    This script performs the trainsing, evaling and testing state of the model.\\n    \"\"\"\\n    learning_rate = FLAGS.learning_rate\\n    w_decay_factor = FLAGS.w_decay_factor\\n    num_steps = FLAGS.num_steps\\n    opt_method = FLAGS.opt_method\\n    feature_columns = FLAGS.feature_columns.split(\\',\\')\\n\\n    # Load dataset.\\n    dataset = read_dataset(\"data/train.csv\")\\n\\n    # Data processing.\\n    train_set = preprocess_data(dataset, feature_columns=feature_columns,\\n                                squared_features=True)\\n\\n    # Initialize model.\\n    ndim = train_set[0].shape[1]\\n    model = LinearRegression(ndim, \\'zeros\\')\\n\\n    # Train model.\\n    if opt_method == \\'iter\\':\\n        # Perform gradient descent.\\n        train_model(train_set, model, learning_rate, num_steps=num_steps)\\n        print(\\'Performed gradient descent.\\')\\n    else:\\n        # Compute closed form solution.\\n        train_model_analytic(train_set, model)\\n        print(\\'Closed form solution.\\')\\n\\n    train_loss = eval_model(train_set, model)\\n    print(\"Train loss: %s\" % train_loss)\\n\\n    # Plot the x vs. y if one dimension.\\n    if train_set[0].shape[1] == 1:\\n        plot_x_vs_y(train_set, model)\\n\\n    # Eval model.\\n    raw_eval = read_dataset(\"data/val.csv\")\\n    eval_set = preprocess_data(raw_eval, feature_columns=feature_columns,\\n                               squared_features=True)\\n    eval_loss = eval_model(eval_set, model)\\n    print(\"Eval loss: %s\" % eval_loss)\\n\\n    # Test model.\\n    raw_test = read_dataset(\"data/test.csv\")\\n    test_set = preprocess_data(raw_test, feature_columns=feature_columns,\\n                               squared_features=True)\\n    test_loss = eval_model(test_set, model)\\n    print(\"Test loss: %s\" % test_loss)\\n\\n\\nif __name__ == \\'__main__\\':\\n    tf.app.run()\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Main function for train, eval, and test.\"\"\"\n",
    "\n",
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from models.linear_regression import LinearRegression\n",
    "from train_eval_model import train_model, eval_model, train_model_analytic\n",
    "from utils.io_tools import read_dataset\n",
    "from utils.data_tools import preprocess_data\n",
    "from utils.plot_tools import plot_x_vs_y\n",
    "\n",
    "'''\n",
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "flags.DEFINE_float('learning_rate', 0.00001, 'Initial learning rate.')\n",
    "flags.DEFINE_float('w_decay_factor', 0.0001, 'Weight decay factor.')\n",
    "flags.DEFINE_integer('num_steps', 100000, 'Number of update steps to run.')\n",
    "flags.DEFINE_string('opt_method', 'analytic', 'Supports [\"iter\", \"analytic\"]')\n",
    "flags.DEFINE_string(\n",
    "    'feature_columns',\n",
    "    'OverallQual,BldgType',\n",
    "    'Comma separated feature names.')\n",
    "'''\n",
    "'''\n",
    "def main(_):\n",
    "    \"\"\"High level pipeline.\n",
    "    This script performs the trainsing, evaling and testing state of the model.\n",
    "    \"\"\"\n",
    "    learning_rate = FLAGS.learning_rate\n",
    "    w_decay_factor = FLAGS.w_decay_factor\n",
    "    num_steps = FLAGS.num_steps\n",
    "    opt_method = FLAGS.opt_method\n",
    "    feature_columns = FLAGS.feature_columns.split(',')\n",
    "\n",
    "    # Load dataset.\n",
    "    dataset = read_dataset(\"data/train.csv\")\n",
    "\n",
    "    # Data processing.\n",
    "    train_set = preprocess_data(dataset, feature_columns=feature_columns,\n",
    "                                squared_features=True)\n",
    "\n",
    "    # Initialize model.\n",
    "    ndim = train_set[0].shape[1]\n",
    "    model = LinearRegression(ndim, 'zeros')\n",
    "\n",
    "    # Train model.\n",
    "    if opt_method == 'iter':\n",
    "        # Perform gradient descent.\n",
    "        train_model(train_set, model, learning_rate, num_steps=num_steps)\n",
    "        print('Performed gradient descent.')\n",
    "    else:\n",
    "        # Compute closed form solution.\n",
    "        train_model_analytic(train_set, model)\n",
    "        print('Closed form solution.')\n",
    "\n",
    "    train_loss = eval_model(train_set, model)\n",
    "    print(\"Train loss: %s\" % train_loss)\n",
    "\n",
    "    # Plot the x vs. y if one dimension.\n",
    "    if train_set[0].shape[1] == 1:\n",
    "        plot_x_vs_y(train_set, model)\n",
    "\n",
    "    # Eval model.\n",
    "    raw_eval = read_dataset(\"data/val.csv\")\n",
    "    eval_set = preprocess_data(raw_eval, feature_columns=feature_columns,\n",
    "                               squared_features=True)\n",
    "    eval_loss = eval_model(eval_set, model)\n",
    "    print(\"Eval loss: %s\" % eval_loss)\n",
    "\n",
    "    # Test model.\n",
    "    raw_test = read_dataset(\"data/test.csv\")\n",
    "    test_set = preprocess_data(raw_test, feature_columns=feature_columns,\n",
    "                               squared_features=True)\n",
    "    test_loss = eval_model(test_set, model)\n",
    "    print(\"Test loss: %s\" % test_loss)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    tf.app.run()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.0000000001\n",
    "w_decay_factor = 0.001\n",
    "num_steps = 20000#FLAGS.num_steps\n",
    "opt_method = 'analytic'#FLAGS.opt_method\n",
    "feature_columns = ('BldgType,OverallQual,GrLivArea,GarageArea').split(',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = read_dataset(\"data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_set = preprocess_data(dataset, feature_columns=feature_columns,\n",
    "                                squared_features=False)\n",
    "#print(train_set[0][1:100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "ndim = train_set[0].shape[1]\n",
    "model = LinearRegression(ndim, 'ones')\n",
    "print(train_set[0].shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((1000, 1), <class 'numpy.ndarray'>)\n"
     ]
    }
   ],
   "source": [
    "#train_model_analytic(train_set, model)\n",
    "f = model.forward(train_set[0])\n",
    "print((f.shape, type(f[0])))\n",
    "#print(f[0], y[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(model.backward(0,0))\n",
    "y = np.array(train_set[1]).astype(float)\n",
    "x = np.array(train_set[0]).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -1.55056497e+08]\n",
      " [ -2.94029000e+06]\n",
      " [ -4.79732500e+06]\n",
      " [ -1.36989600e+07]\n",
      " [ -3.79941100e+06]\n",
      " [ -1.19218669e+09]\n",
      " [ -3.02218356e+11]\n",
      " [ -9.61030120e+10]\n",
      " [ -1.80292483e+08]]\n"
     ]
    }
   ],
   "source": [
    "#train_model_analytic(train_set, model)\n",
    "total_grad = model.backward(f, y)\n",
    "print(total_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 1)\n"
     ]
    }
   ],
   "source": [
    "print(total_grad.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(model.x)\n",
    "f = model.forward(train_set[0])\n",
    "#print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.27698485e+04],\n",
       "       [  2.41729236e+04],\n",
       "       [  1.55999930e+04],\n",
       "       [  2.62865625e+04],\n",
       "       [  5.50129151e+03],\n",
       "       [  2.68392425e+04],\n",
       "       [  5.51245916e+01],\n",
       "       [  7.44718899e+01],\n",
       "       [ -1.31299458e+05]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model_analytic(train_set, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.29606883708e+14\n"
     ]
    }
   ],
   "source": [
    "print(np.linalg.det(np.dot(np.transpose(model.x), model.x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 99.5% ... Training loss total: 756908719293.0Performed gradient descent.\n"
     ]
    }
   ],
   "source": [
    "train_model(train_set, model, learning_rate, num_steps=num_steps)\n",
    "print('Performed gradient descent.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  3.27698441e+04]\n",
      " [  2.41729205e+04]\n",
      " [  1.55999910e+04]\n",
      " [  2.62865591e+04]\n",
      " [  5.50129072e+03]\n",
      " [  2.68392385e+04]\n",
      " [  5.51202588e+01]\n",
      " [  7.44964360e+01]\n",
      " [ -1.31299442e+05]]\n"
     ]
    }
   ],
   "source": [
    "print(model.w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print((model.w-train_model_analytic(train_set, model))/np.max(model.w))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "756905367433.0\n"
     ]
    }
   ],
   "source": [
    "print(eval_model(train_set, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [tensorflow]",
   "language": "python",
   "name": "Python [tensorflow]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
