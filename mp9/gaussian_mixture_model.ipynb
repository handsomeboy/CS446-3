{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Implements the Gaussian Mixture model, and trains using EM algorithm.\"\"\"\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "\n",
    "class GaussianMixtureModel(object):\n",
    "    \"\"\"Gaussian Mixture Model\"\"\"\n",
    "    def __init__(self, n_dims, n_components=1,\n",
    "                 max_iter=10,\n",
    "                 reg_covar=1e-6):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            n_dims: The dimension of the feature.\n",
    "            n_components: Number of Gaussians in the GMM.\n",
    "            max_iter: Number of steps to run EM.\n",
    "            reg_covar: Amount to regularize the covariance matrix, (i.e. add\n",
    "                to the diagonal of covariance matrices).\n",
    "        \"\"\"\n",
    "        self._n_dims = n_dims\n",
    "        self._n_components = n_components\n",
    "        self._max_iter = max_iter\n",
    "        self._reg_covar = reg_covar\n",
    "\n",
    "        # Randomly Initialize model parameters\n",
    "        self._mu = np.zeros((n_components, n_dims)) # np.array of size (n_components, n_dims)\n",
    "        # Initialized with uniform distribution.\n",
    "        self._pi = np.array([1.0/n_components for i in range(n_components)]).reshape((-1,1))# np.array of size (n_components, 1)\n",
    "        # Initialized with identity.\n",
    "        self._sigma = np.array([1000*np.eye(n_dims) for i in range(n_components)])  # np.array of size (n_components, n_dims, n_dims)\n",
    "\n",
    "    def fit(self, x):\n",
    "        \"\"\"Runs EM steps.\n",
    "\n",
    "        Runs EM steps for max_iter number of steps.\n",
    "\n",
    "        Args:\n",
    "            x(numpy.ndarray): Feature array of dimension (N, ndims).\n",
    "        \"\"\"\n",
    "        if self._mu.all() == 0:\n",
    "            l_rand = np.random.choice(range(len(x)), self._n_components, replace=False)\n",
    "            self._mu = x[l_rand]\n",
    "            print(l_rand)\n",
    "            #self._mu = x[:self._n_components,:]\n",
    "        for i in range(self._max_iter):\n",
    "            print(\"iteration \"+str(i))\n",
    "            z_ik = self._e_step(x)\n",
    "            self._m_step(x, z_ik)\n",
    "            \n",
    "        \n",
    "\n",
    "    def _e_step(self, x):\n",
    "        \"\"\"E step.\n",
    "\n",
    "        Wraps around get_posterior.\n",
    "\n",
    "        Args:\n",
    "            x(numpy.ndarray): Feature array of dimension (N, ndims).\n",
    "        Returns:\n",
    "            z_ik(numpy.ndarray): Array containing the posterior probability\n",
    "                of each example, dimension (N, n_components).\n",
    "        \"\"\"\n",
    "        return self.get_posterior(x) \n",
    "\n",
    "    def _m_step(self, x, z_ik):\n",
    "        \"\"\"M step, update the parameters.\n",
    "\n",
    "        Args:\n",
    "            x(numpy.ndarray): Feature array of dimension (N, ndims).\n",
    "            z_ik(numpy.ndarray): Array containing the posterior probability\n",
    "                of each example, dimension (N, n_components).\n",
    "                (Alternate way of representing categorical distribution of z_i)\n",
    "        \"\"\"\n",
    "        # Update the parameters.\n",
    "        self._pi = np.sum(z_ik, axis=0)/len(x)\n",
    "        for k in range(self._n_components):\n",
    "            self._mu[k] = np.matmul(z_ik[:,k],x)/(len(x)*self._pi[k])\n",
    "            #self._sigma[k] = np.cov((x-self._mu[k]).T, aweights=z_ik[:,k], ddof=0, bias=True)\n",
    "            #self._sigma[k] = np.array([[self._sigma[k][i][j]+self._reg_covar if i==j else 0*self._sigma[k][i][j] for i in range(self._sigma[k].shape[0])] for j in range(self._sigma[k].shape[0])])\n",
    "            self._sigma[k] = np.zeros_like(self._sigma[k])\n",
    "            for i in range(len(x)):\n",
    "                self._sigma[k] += z_ik[i,k]*np.matmul((x[i]-self._mu[k]).reshape((2,1)),(x[i]-self._mu[k]).reshape((1,2)))\n",
    "                \n",
    "            self._sigma[k] /= (len(x)*self._pi[k] )\n",
    "            self._sigma[k] += self._reg_covar*np.identity(self._sigma[k].shape[0])\n",
    "            self._sigma[k] = np.array([[self._sigma[k][i][j]+self._reg_covar if i==j else 0*self._sigma[k][i][j] for i in range(self._sigma[k].shape[0])] for j in range(self._sigma[k].shape[0])])\n",
    "                                                    \n",
    "            print(self._sigma[k])\n",
    "        pass\n",
    "\n",
    "    def get_conditional(self, x):\n",
    "        \"\"\"Computes the conditional probability.\n",
    "\n",
    "        p(x^(i)|z_ik=1)\n",
    "\n",
    "        Args:\n",
    "            x(numpy.ndarray): Feature array of dimension (N, ndims).\n",
    "        Returns:\n",
    "            ret(numpy.ndarray): The conditional probability for each example,\n",
    "                dimension (N,, n_components).\n",
    "        \"\"\"\n",
    "        ret = np.zeros((len(x), self._n_components))\n",
    "        for k in range(self._n_components):\n",
    "            ret[:,k] = self._multivariate_gaussian(x, self._mu[k], self._sigma[k])\n",
    "        return ret\n",
    "\n",
    "    def get_marginals(self, x):\n",
    "        \"\"\"Computes the marginal probability.\n",
    "\n",
    "        p(x^(i)|pi, mu, sigma)\n",
    "\n",
    "        Args:\n",
    "             x(numpy.ndarray): Feature array of dimension (N, ndims).\n",
    "        Returns:\n",
    "            (1) The marginal probability for each example, dimension (N,).\n",
    "        \"\"\"\n",
    "        marginal = np.array((len(x),))\n",
    "        marginal = np.matmul(self.get_conditional(x), self._pi).reshape((-1,))\n",
    "        return marginal \n",
    "\n",
    "    def get_posterior(self, x):\n",
    "        \"\"\"Computes the posterior probability.\n",
    "\n",
    "        p(z_{ik}=1|x^(i))\n",
    "\n",
    "        Args:\n",
    "            x(numpy.ndarray): Feature array of dimension (N, ndims).\n",
    "        Returns:\n",
    "            z_ik(numpy.ndarray): Array containing the posterior probability\n",
    "                of each example, dimension (N, n_components).\n",
    "        \"\"\"\n",
    "        z_ik = np.zeros((len(x), self._n_components))\n",
    "        p_cond = self.get_conditional(x)\n",
    "        for k in range(self._n_components):\n",
    "            z_ik[:,k] =(p_cond[:,k]*self._pi[k] + self._reg_covar) / (self.get_marginals(x)+ self._n_components*self._reg_covar)\n",
    "            #z_ik[:,k] =(p_cond[:,k]*self._pi[k]) / (self.get_marginals(x))\n",
    "            if np.sum(z_ik[:,k]) == 0:\n",
    "                print(\"error\")\n",
    "        return z_ik\n",
    "\n",
    "    def _multivariate_gaussian(self, x, mu_k, sigma_k):\n",
    "        \"\"\"Multivariate Gaussian, implemented for you.\n",
    "        Args:\n",
    "            x(numpy.ndarray): Array containing the features of dimension (N,\n",
    "                ndims)\n",
    "            mu_k(numpy.ndarray): Array containing one single mean (ndims,1)\n",
    "            sigma_k(numpy.ndarray): Array containing one signle covariance matrix\n",
    "                (ndims, ndims)\n",
    "        \"\"\"\n",
    "        return multivariate_normal.pdf(x, mu_k, sigma_k)\n",
    "\n",
    "    def supervised_fit(self, x, y):\n",
    "        \"\"\"Assign each cluster with a label through counting.\n",
    "        For each cluster, find the most common digit using the provided (x,y)\n",
    "        and store it in self.cluster_label_map.\n",
    "        self.cluster_label_map should be a list of length n_components,\n",
    "        where each element maps to the most common digit in that cluster.\n",
    "        (e.g. If self.cluster_label_map[0] = 9. Then the most common digit\n",
    "        in cluster 0 is 9.\n",
    "        Args:\n",
    "            x(numpy.ndarray): Array containing the feature of dimension (N,\n",
    "                ndims).\n",
    "            y(numpy.ndarray): Array containing the label of dimension (N,)\n",
    "        \"\"\"\n",
    "        self.cluster_label_map = []\n",
    "        p = self.get_posterior(x)\n",
    "        data_to_cluster = np.argmax(p, axis=1)\n",
    "        label = np.zeros((len(np.unique(y)),self._n_components))\n",
    "        unique_label = np.unique(y).tolist()\n",
    "        \n",
    "        for i in range(len(x)):\n",
    "            labelindx = unique_label.index(y[i])\n",
    "            label[labelindx,data_to_cluster[i]] +=1\n",
    "        convertor = np.argmax(label, axis=0)\n",
    "        for i in range(len(convertor)):\n",
    "            self.cluster_label_map.append(unique_label[convertor[i]])\n",
    "        return self.cluster_label_map\n",
    "\n",
    "    def supervised_predict(self, x):\n",
    "        \"\"\"Predict a label for each example in x.\n",
    "        Find the get the cluster assignment for each x, then use\n",
    "        self.cluster_label_map to map to the corresponding digit.\n",
    "        Args:\n",
    "            x(numpy.ndarray): Array containing the feature of dimension (N,\n",
    "                ndims).\n",
    "        Returns:\n",
    "            y_hat(numpy.ndarray): Array containing the predicted label for each\n",
    "            x, dimension (N,)\n",
    "        \"\"\"\n",
    "\n",
    "        z_ik = self.get_posterior(x)\n",
    "        label = np.argmax(z_ik, axis=1)\n",
    "        y_hat =[]\n",
    "        for i in range(len(x)):\n",
    "            y_hat.append(self.cluster_label_map[label[i]])\n",
    "\n",
    "        return np.array(y_hat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[113  34]\n",
      "iteration 0\n",
      "[[ 24.7578719   0.       ]\n",
      " [  0.         25.0766864]]\n",
      "[[ 24.74805461   0.        ]\n",
      " [  0.          25.04453284]]\n",
      "iteration 1\n",
      "[[ 24.59406014   0.        ]\n",
      " [  0.          24.92319772]]\n",
      "[[ 24.57522597   0.        ]\n",
      " [  0.          24.85746721]]\n",
      "iteration 2\n",
      "[[ 23.95830431   0.        ]\n",
      " [  0.          24.30151115]]\n",
      "[[ 23.92163155   0.        ]\n",
      " [  0.          24.17384849]]\n",
      "iteration 3\n",
      "[[ 21.57326867   0.        ]\n",
      " [  0.          21.92547405]]\n",
      "[[ 21.50692254   0.        ]\n",
      " [  0.          21.69130987]]\n",
      "iteration 4\n",
      "[[ 13.76357296   0.        ]\n",
      " [  0.          14.06682952]]\n",
      "[[ 13.69548453   0.        ]\n",
      " [  0.          13.74413034]]\n",
      "iteration 5\n",
      "[[ 1.70825475  0.        ]\n",
      " [ 0.          1.85873507]]\n",
      "[[ 1.75966446  0.        ]\n",
      " [ 0.          1.69057088]]\n",
      "iteration 6\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112281]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 7\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 8\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 9\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 10\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 11\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 12\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 13\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 14\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 15\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 16\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 17\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 18\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 19\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 20\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 21\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 22\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 23\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 24\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 25\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 26\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 27\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 28\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 29\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 30\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 31\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 32\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 33\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 34\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 35\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 36\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 37\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 38\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 39\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 40\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 41\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 42\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 43\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 44\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 45\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 46\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 47\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 48\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 49\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 50\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 51\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 52\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 53\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 54\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 55\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 56\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 57\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 58\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 59\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 60\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 61\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 62\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 63\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 64\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 65\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 66\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 67\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 68\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 69\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 70\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 71\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 72\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 73\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 74\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 75\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 76\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 77\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 78\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 79\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 80\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 81\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 82\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 83\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 84\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 85\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 86\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 87\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 88\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 89\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 90\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 91\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 92\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 93\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 94\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 95\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 96\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 97\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 98\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n",
      "iteration 99\n",
      "[[ 0.80943267  0.        ]\n",
      " [ 0.          0.94112282]]\n",
      "[[ 0.84771013 -0.        ]\n",
      " [-0.          0.76960253]]\n"
     ]
    }
   ],
   "source": [
    "from utils import io_tools\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from utils import io_tools\n",
    "\n",
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "max_iter=100\n",
    "n_components=2\n",
    "reg_covar=1e-2\n",
    "#print(os.getcwd())\n",
    "_, unlabeled_data = io_tools.read_dataset('data/simple_test.csv')\n",
    "unlabeled_data = unlabeled_data[0:4000]\n",
    "n_dims = unlabeled_data.shape[1]\n",
    "#print(n_dims)\n",
    "\n",
    "    # Initialize model.\n",
    "model = GaussianMixtureModel(n_dims, n_components=n_components,\n",
    "                                     max_iter=max_iter,reg_covar=1e-12)\n",
    "\n",
    "\n",
    "#model.get_conditional(unlabeled_data)\n",
    "#model.get_conditional(unlabeled_data)\n",
    "    # Unsupervised training.\n",
    "model.fit(unlabeled_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "train_label, train_data = io_tools.read_dataset('data/simple_test.csv')\n",
    "print(model.supervised_fit(train_data[:-20], train_label[:-20]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    # Eval model.\n",
    "eval_label, eval_data = io_tools.read_dataset('data/simple_test.csv')\n",
    "y_hat_eval = model.supervised_predict(eval_data[-20:])\n",
    "\n",
    "acc = np.sum(y_hat_eval == eval_label[-20:]) / (1.*eval_data.shape[0])\n",
    "print(\"Accuracy: %s\" % acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.])"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p=model.get_posterior(train_data)\n",
    "data_to_cluster=np.argmax(p, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(data_to_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [tensorflow]",
   "language": "python",
   "name": "Python [tensorflow]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
