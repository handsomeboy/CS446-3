{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Implements the Gaussian Mixture model, and trains using EM algorithm.\"\"\"\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "\n",
    "class GaussianMixtureModel(object):\n",
    "    \"\"\"Gaussian Mixture Model\"\"\"\n",
    "    def __init__(self, n_dims, n_components=1,\n",
    "                 max_iter=10,\n",
    "                 reg_covar=1e-6):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            n_dims: The dimension of the feature.\n",
    "            n_components: Number of Gaussians in the GMM.\n",
    "            max_iter: Number of steps to run EM.\n",
    "            reg_covar: Amount to regularize the covariance matrix, (i.e. add\n",
    "                to the diagonal of covariance matrices).\n",
    "        \"\"\"\n",
    "        self._n_dims = n_dims\n",
    "        self._n_components = n_components\n",
    "        self._max_iter = max_iter\n",
    "        self._reg_covar = reg_covar\n",
    "\n",
    "        # Randomly Initialize model parameters\n",
    "        self._mu = np.zeros((n_components, n_dims)) # np.array of size (n_components, n_dims)\n",
    "\n",
    "        # Initialized with uniform distribution.\n",
    "        self._pi = np.array([1.0/n_components for i in range(n_components)]).reshape((-1,1))# np.array of size (n_components, 1)\n",
    "\n",
    "        # Initialized with identity.\n",
    "        self._sigma = np.array([100*np.eye(n_dims) for i in range(n_components)])  # np.array of size (n_components, n_dims, n_dims)\n",
    "\n",
    "    def fit(self, x):\n",
    "        \"\"\"Runs EM steps.\n",
    "\n",
    "        Runs EM steps for max_iter number of steps.\n",
    "\n",
    "        Args:\n",
    "            x(numpy.ndarray): Feature array of dimension (N, ndims).\n",
    "        \"\"\"\n",
    "        if self._mu.all() == 0:\n",
    "            l_rand = np.random.choice(range(len(x)), self._n_components, replace=False)\n",
    "            self._mu = x[l_rand]\n",
    "            print(self._mu)\n",
    "        for i in range(max_iter):\n",
    "            print(\"iteration \"+str(i))\n",
    "            z_ik = self._e_step(x)\n",
    "            print(self._mu)\n",
    "            self._m_step(x, z_ik)\n",
    "            print(\"Iteration End:  \"+ str(i))\n",
    "            print(self._mu)\n",
    "            \n",
    "        \n",
    "\n",
    "    def _e_step(self, x):\n",
    "        \"\"\"E step.\n",
    "\n",
    "        Wraps around get_posterior.\n",
    "\n",
    "        Args:\n",
    "            x(numpy.ndarray): Feature array of dimension (N, ndims).\n",
    "        Returns:\n",
    "            z_ik(numpy.ndarray): Array containing the posterior probability\n",
    "                of each example, dimension (N, n_components).\n",
    "        \"\"\"\n",
    "        \n",
    "        return self.get_posterior(x) \n",
    "\n",
    "    def _m_step(self, x, z_ik):\n",
    "        \"\"\"M step, update the parameters.\n",
    "\n",
    "        Args:\n",
    "            x(numpy.ndarray): Feature array of dimension (N, ndims).\n",
    "            z_ik(numpy.ndarray): Array containing the posterior probability\n",
    "                of each example, dimension (N, n_components).\n",
    "                (Alternate way of representing categorical distribution of z_i)\n",
    "        \"\"\"\n",
    "        # Update the parameters.\n",
    "        self._pi = np.sum(z_ik, axis=0)/len(x)\n",
    "        self._mu = np.dot(z_ik.T,x)\n",
    "#         for k in range(self._n_components):\n",
    "#             self._mu[k] = np.dot(x.T, z_ik[:,k])/(len(x)*self._pi[k])\n",
    "            #self._sigma[k] = np.sum(z_ik[:,k]@(x-self._mu[k])@(x-self._mu[k]).T, axis=0)/(len(x)*self._pi[k])\n",
    "        pass\n",
    "\n",
    "    def get_conditional(self, x):\n",
    "        \"\"\"Computes the conditional probability.\n",
    "\n",
    "        p(x^(i)|z_ik=1)\n",
    "\n",
    "        Args:\n",
    "            x(numpy.ndarray): Feature array of dimension (N, ndims).\n",
    "        Returns:\n",
    "            ret(numpy.ndarray): The conditional probability for each example,\n",
    "                dimension (N,, n_components).\n",
    "        \"\"\"\n",
    "        ret = np.zeros((len(x), self._n_components))\n",
    "        for k in range(self._n_components):\n",
    "            ret[:,k] = self._multivariate_gaussian(x, self._mu[k], self._sigma[k])\n",
    "\n",
    "        return ret\n",
    "\n",
    "    def get_marginals(self, x):\n",
    "        \"\"\"Computes the marginal probability.\n",
    "\n",
    "        p(x^(i)|pi, mu, sigma)\n",
    "\n",
    "        Args:\n",
    "             x(numpy.ndarray): Feature array of dimension (N, ndims).\n",
    "        Returns:\n",
    "            (1) The marginal probability for each example, dimension (N,).\n",
    "        \"\"\"\n",
    "        marginal = np.array((len(x),))\n",
    "        marginal = np.matmul(self.get_conditional(x), self._pi)\n",
    "        return marginal\n",
    "\n",
    "    def get_posterior(self, x):\n",
    "        \"\"\"Computes the posterior probability.\n",
    "\n",
    "        p(z_{ik}=1|x^(i))\n",
    "\n",
    "        Args:\n",
    "            x(numpy.ndarray): Feature array of dimension (N, ndims).\n",
    "        Returns:\n",
    "            z_ik(numpy.ndarray): Array containing the posterior probability\n",
    "                of each example, dimension (N, n_components).\n",
    "        \"\"\"\n",
    "        z_ik = np.zeros((len(x), self._n_components))\n",
    "        p_cond = self.get_conditional(x)\n",
    "        for k in range(self._n_components):\n",
    "            z_ik[:,k] =p_cond[:,k]*self._pi[k]\n",
    "        z_ik = np.divide(z_ik.T,self.get_marginals(x))\n",
    "        return z_ik\n",
    "\n",
    "    def _multivariate_gaussian(self, x, mu_k, sigma_k):\n",
    "        \"\"\"Multivariate Gaussian, implemented for you.\n",
    "        Args:\n",
    "            x(numpy.ndarray): Array containing the features of dimension (N,\n",
    "                ndims)\n",
    "            mu_k(numpy.ndarray): Array containing one single mean (ndims,1)\n",
    "            sigma_k(numpy.ndarray): Array containing one signle covariance matrix\n",
    "                (ndims, ndims)\n",
    "        \"\"\"\n",
    "        return multivariate_normal.pdf(x, mu_k, sigma_k)\n",
    "\n",
    "    def supervised_fit(self, x, y):\n",
    "        \"\"\"Assign each cluster with a label through counting.\n",
    "        For each cluster, find the most common digit using the provided (x,y)\n",
    "        and store it in self.cluster_label_map.\n",
    "        self.cluster_label_map should be a list of length n_components,\n",
    "        where each element maps to the most common digit in that cluster.\n",
    "        (e.g. If self.cluster_label_map[0] = 9. Then the most common digit\n",
    "        in cluster 0 is 9.\n",
    "        Args:\n",
    "            x(numpy.ndarray): Array containing the feature of dimension (N,\n",
    "                ndims).\n",
    "            y(numpy.ndarray): Array containing the label of dimension (N,)\n",
    "        \"\"\"\n",
    "\n",
    "        self.cluster_label_map = []\n",
    "        pass\n",
    "\n",
    "    def supervised_predict(self, x):\n",
    "        \"\"\"Predict a label for each example in x.\n",
    "        Find the get the cluster assignment for each x, then use\n",
    "        self.cluster_label_map to map to the corresponding digit.\n",
    "        Args:\n",
    "            x(numpy.ndarray): Array containing the feature of dimension (N,\n",
    "                ndims).\n",
    "        Returns:\n",
    "            y_hat(numpy.ndarray): Array containing the predicted label for each\n",
    "            x, dimension (N,)\n",
    "        \"\"\"\n",
    "\n",
    "        z_ik = self.get_posterior(x)\n",
    "        y_hat = []\n",
    "\n",
    "        return np.array(y_hat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8.51010418  9.96110009]\n",
      " [ 0.77900748 -0.94213719]]\n",
      "iteration 0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (200,2) (1,200) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-a86ad304ab7b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;31m# Unsupervised training.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munlabeled_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-35-c5dcfb810c9f>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"iteration \"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m             \u001b[0mz_ik\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_e_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_m_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz_ik\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-35-c5dcfb810c9f>\u001b[0m in \u001b[0;36m_e_step\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     66\u001b[0m         \"\"\"\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_posterior\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_m_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz_ik\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-35-c5dcfb810c9f>\u001b[0m in \u001b[0;36mget_posterior\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    131\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_components\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m             \u001b[0mz_ik\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mp_cond\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m         \u001b[0mz_ik\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdivide\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz_ik\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_marginals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    134\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mz_ik\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (200,2) (1,200) "
     ]
    }
   ],
   "source": [
    "from utils import io_tools\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from utils import io_tools\n",
    "\n",
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "max_iter=100\n",
    "n_components=2\n",
    "#print(os.getcwd())\n",
    "_, unlabeled_data = io_tools.read_dataset('data/simple_test.csv')\n",
    "n_dims = unlabeled_data.shape[1]\n",
    "#print(n_dims)\n",
    "\n",
    "    # Initialize model.\n",
    "model = GaussianMixtureModel(n_dims, n_components=n_components,\n",
    "                                     max_iter=max_iter)\n",
    "\n",
    "    # Unsupervised training.\n",
    "model.fit(unlabeled_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.get_posterior(unlabeled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [tensorflow]",
   "language": "python",
   "name": "Python [tensorflow]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
