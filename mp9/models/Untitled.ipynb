{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Implements the Gaussian Mixture model, and trains using EM algorithm.\"\"\"\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "\n",
    "class GaussianMixtureModel(object):\n",
    "    \"\"\"Gaussian Mixture Model\"\"\"\n",
    "    def __init__(self, n_dims, n_components=1,\n",
    "                 max_iter=10,\n",
    "                 reg_covar=1e-6):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            n_dims: The dimension of the feature.\n",
    "            n_components: Number of Gaussians in the GMM.\n",
    "            max_iter: Number of steps to run EM.\n",
    "            reg_covar: Amount to regularize the covariance matrix, (i.e. add\n",
    "                to the diagonal of covariance matrices).\n",
    "        \"\"\"\n",
    "        self._n_dims = n_dims\n",
    "        self._n_components = n_components\n",
    "        self._max_iter = max_iter\n",
    "        self._reg_covar = reg_covar\n",
    "\n",
    "        # Randomly Initialize model parameters\n",
    "        self._mu = np.zeros((n_components, n_dims)) # np.array of size (n_components, n_dims)\n",
    "\n",
    "        # Initialized with uniform distribution.\n",
    "        self._pi = np.array([1.0/n_components for i in range(n_components)]).reshape((-1,1))# np.array of size (n_components, 1)\n",
    "\n",
    "        # Initialized with identity.\n",
    "        self._sigma = np.array([50*np.eye(n_dims) for i in range(n_components)])  # np.array of size (n_components, n_dims, n_dims)\n",
    "\n",
    "    def fit(self, x):\n",
    "        \"\"\"Runs EM steps.\n",
    "\n",
    "        Runs EM steps for max_iter number of steps.\n",
    "\n",
    "        Args:\n",
    "            x(numpy.ndarray): Feature array of dimension (N, ndims).\n",
    "        \"\"\"\n",
    "        if self._mu.all() == 0:\n",
    "            l_rand = np.random.choice(range(len(x)), self._n_components, replace=False)\n",
    "            self._mu = x[l_rand]\n",
    "            print(l_rand)\n",
    "        for i in range(max_iter):\n",
    "            print(\"iteration \"+str(i))\n",
    "            z_ik = self._e_step(x)\n",
    "            self._m_step(x, z_ik)\n",
    "            print(self._mu)\n",
    "            print(\"Iteration End:  \"+ str(i))\n",
    "            \n",
    "        \n",
    "\n",
    "    def _e_step(self, x):\n",
    "        \"\"\"E step.\n",
    "\n",
    "        Wraps around get_posterior.\n",
    "\n",
    "        Args:\n",
    "            x(numpy.ndarray): Feature array of dimension (N, ndims).\n",
    "        Returns:\n",
    "            z_ik(numpy.ndarray): Array containing the posterior probability\n",
    "                of each example, dimension (N, n_components).\n",
    "        \"\"\"\n",
    "        \n",
    "        return self.get_posterior(x) \n",
    "\n",
    "    def _m_step(self, x, z_ik):\n",
    "        \"\"\"M step, update the parameters.\n",
    "\n",
    "        Args:\n",
    "            x(numpy.ndarray): Feature array of dimension (N, ndims).\n",
    "            z_ik(numpy.ndarray): Array containing the posterior probability\n",
    "                of each example, dimension (N, n_components).\n",
    "                (Alternate way of representing categorical distribution of z_i)\n",
    "        \"\"\"\n",
    "        # Update the parameters.\n",
    "        self._pi = np.sum(z_ik, axis=0)/len(x)\n",
    "        \n",
    "        for k in range(self._n_components):\n",
    "            self._mu[k] = np.matmul(z_ik[:,k],x)/(len(x)*self._pi[k])\n",
    "            self._sigma[k] = np.cov((x-self._mu[k]).T, aweights=z_ik[:,k], ddof=0, bias=True)\n",
    "        pass\n",
    "\n",
    "    def get_conditional(self, x):\n",
    "        \"\"\"Computes the conditional probability.\n",
    "\n",
    "        p(x^(i)|z_ik=1)\n",
    "\n",
    "        Args:\n",
    "            x(numpy.ndarray): Feature array of dimension (N, ndims).\n",
    "        Returns:\n",
    "            ret(numpy.ndarray): The conditional probability for each example,\n",
    "                dimension (N,, n_components).\n",
    "        \"\"\"\n",
    "        ret = np.zeros((len(x), self._n_components))\n",
    "        for k in range(self._n_components):\n",
    "            ret[:,k] = self._multivariate_gaussian(x, self._mu[k], self._sigma[k])\n",
    "\n",
    "        return ret\n",
    "\n",
    "    def get_marginals(self, x):\n",
    "        \"\"\"Computes the marginal probability.\n",
    "\n",
    "        p(x^(i)|pi, mu, sigma)\n",
    "\n",
    "        Args:\n",
    "             x(numpy.ndarray): Feature array of dimension (N, ndims).\n",
    "        Returns:\n",
    "            (1) The marginal probability for each example, dimension (N,).\n",
    "        \"\"\"\n",
    "        marginal = np.array((len(x),))\n",
    "        marginal = np.matmul(self.get_conditional(x), self._pi).reshape((-1,))\n",
    "        return marginal \n",
    "\n",
    "    def get_posterior(self, x):\n",
    "        \"\"\"Computes the posterior probability.\n",
    "\n",
    "        p(z_{ik}=1|x^(i))\n",
    "\n",
    "        Args:\n",
    "            x(numpy.ndarray): Feature array of dimension (N, ndims).\n",
    "        Returns:\n",
    "            z_ik(numpy.ndarray): Array containing the posterior probability\n",
    "                of each example, dimension (N, n_components).\n",
    "        \"\"\"\n",
    "        z_ik = np.zeros((len(x), self._n_components))\n",
    "        p_cond = self.get_conditional(x)\n",
    "        for k in range(self._n_components):\n",
    "            z_ik[:,k] =(p_cond[:,k]*self._pi[k] + self._reg_covar) / (self.get_marginals(x)+ self._n_components*self._reg_covar)\n",
    "\n",
    "            if np.sum(z_ik[:,k]) == 0:\n",
    "                print(\"error\")\n",
    "        return z_ik\n",
    "\n",
    "    def _multivariate_gaussian(self, x, mu_k, sigma_k):\n",
    "        \"\"\"Multivariate Gaussian, implemented for you.\n",
    "        Args:\n",
    "            x(numpy.ndarray): Array containing the features of dimension (N,\n",
    "                ndims)\n",
    "            mu_k(numpy.ndarray): Array containing one single mean (ndims,1)\n",
    "            sigma_k(numpy.ndarray): Array containing one signle covariance matrix\n",
    "                (ndims, ndims)\n",
    "        \"\"\"\n",
    "        return multivariate_normal.pdf(x, mu_k, sigma_k)\n",
    "\n",
    "    def supervised_fit(self, x, y):\n",
    "        \"\"\"Assign each cluster with a label through counting.\n",
    "        For each cluster, find the most common digit using the provided (x,y)\n",
    "        and store it in self.cluster_label_map.\n",
    "        self.cluster_label_map should be a list of length n_components,\n",
    "        where each element maps to the most common digit in that cluster.\n",
    "        (e.g. If self.cluster_label_map[0] = 9. Then the most common digit\n",
    "        in cluster 0 is 9.\n",
    "        Args:\n",
    "            x(numpy.ndarray): Array containing the feature of dimension (N,\n",
    "                ndims).\n",
    "            y(numpy.ndarray): Array containing the label of dimension (N,)\n",
    "        \"\"\"\n",
    "        self.cluster_label_map = []\n",
    "        p = self.get_posterior(x)\n",
    "        data_to_cluster = np.argmax(p, axis=1)\n",
    "        label = np.zeros((len(np.unique(y)),self._n_components))\n",
    "        unique_label = np.unique(y).tolist()\n",
    "        for i in range(len(x)):\n",
    "            labelindx = unique_label.index(y[i])\n",
    "            label[labelindx,data_to_cluster[i]] +=1\n",
    "        convertor = np.argmax(label, axis=0)\n",
    "        for i in range(len(convertor)):\n",
    "            self.cluster_label_map.append(unique_label[convertor[i]])\n",
    "        return self.cluster_label_map\n",
    "\n",
    "    def supervised_predict(self, x):\n",
    "        \"\"\"Predict a label for each example in x.\n",
    "        Find the get the cluster assignment for each x, then use\n",
    "        self.cluster_label_map to map to the corresponding digit.\n",
    "        Args:\n",
    "            x(numpy.ndarray): Array containing the feature of dimension (N,\n",
    "                ndims).\n",
    "        Returns:\n",
    "            y_hat(numpy.ndarray): Array containing the predicted label for each\n",
    "            x, dimension (N,)\n",
    "        \"\"\"\n",
    "\n",
    "        z_ik = self.get_posterior(x)\n",
    "        y_hat =[]\n",
    "        for i in range(len(x)):\n",
    "            for k in range(self._n_components):\n",
    "                if z_ik[i,k]>=max(z_ik[i,:]):\n",
    "                    y_hat.append(self.cluster_label_map[k])\n",
    "\n",
    "        return np.array(y_hat)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [tensorflow]",
   "language": "python",
   "name": "Python [tensorflow]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
