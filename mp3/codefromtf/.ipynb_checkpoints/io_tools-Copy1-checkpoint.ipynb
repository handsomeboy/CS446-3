{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Input and output helpers to load in data.\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "def read_dataset(path_to_dataset_folder,index_filename):\n",
    "    \"\"\" Read dataset into numpy arrays with preprocessing included\n",
    "    Args:\n",
    "        path_to_dataset_folder(str): path to the folder containing samples and indexing.txt\n",
    "        index_filename(str): indexing.txt\n",
    "    Returns:\n",
    "        A(numpy.ndarray): sample feature matrix A = [[1, x1], \n",
    "                                                     [1, x2], \n",
    "                                                     [1, x3],\n",
    "                                                     .......] \n",
    "                                where xi is the 16-dimensional feature of each sample\n",
    "            \n",
    "        T(numpy.ndarray): class label vector T = [y1, y2, y3, ...] \n",
    "                             where yi is +1/-1, the label of each sample \n",
    "    \"\"\"\n",
    "    with open(path_to_dataset_folder+'/'+index_filename, 'r') as f:\n",
    "        label_sample_path = f.readlines()\n",
    "    T = np.array([max(0,float(label_sample_path[i].split(' ')[0])) for i in range(len(label_sample_path))])\n",
    "    sample_path = [label_sample_path[i].split(' ')[1].replace('\\n','') for i in range(len(label_sample_path))]\n",
    "    \n",
    "    A = []\n",
    "    for i in range(len(sample_path)):\n",
    "        with open(path_to_dataset_folder+'/'+sample_path[i], 'r') as f:\n",
    "            row_data = f.read().strip().split('  ')\n",
    "            A.append([1.  if i ==0 else float(row_data[i-1]) for i in range(len(row_data)+1)])\n",
    "    A = np.array(A)\n",
    "    \n",
    "        \n",
    "    \n",
    "    return A, T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, Y_true = read_dataset('C:/Users/PIxel/CS446/mp3/data/trainset','indexing.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0. ...,  1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "print(Y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"logistic model class for binary classification.\"\"\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "class LogisticModel_TF(object):\n",
    "    \n",
    "    def __init__(self, ndims, W_init='zeros'):\n",
    "        \"\"\"Initialize a logistic model.\n",
    "\n",
    "        This function prepares an initialized logistic model.\n",
    "        It will initialize the weight vector, self.W, based on the method\n",
    "        specified in W_init.\n",
    "\n",
    "        We assume that the FIRST index of Weight is the bias term, \n",
    "            Weight = [Bias, W1, W2, W3, ...] \n",
    "            where Wi correspnds to each feature dimension\n",
    "\n",
    "        W_init needs to support:\n",
    "          'zeros': initialize self.W with all zeros.\n",
    "          'ones': initialze self.W with all ones.\n",
    "          'uniform': initialize self.W with uniform random number between [0,1)\n",
    "          'gaussian': initialize self.W with gaussion distribution (0, 0.1)\n",
    "\n",
    "        Args:\n",
    "            ndims(int): feature dimension\n",
    "            W_init(str): types of initialization.\n",
    "        \"\"\"\n",
    "        self.ndims = ndims\n",
    "        self.W_init = W_init\n",
    "        self.W0 = None\n",
    "        ###############################################################\n",
    "        # Fill your code below\n",
    "        ###############################################################\n",
    "        if W_init == 'zeros':\n",
    "            # Hint: self.W0 = tf.zeros([self.ndims+1,1])\n",
    "            self.W0 = tf.zeros([self.ndims, 1])\n",
    "        elif W_init == 'ones':\n",
    "            self.W0 = tf.ones([self.ndims, 1])\n",
    "        elif W_init == 'uniform':\n",
    "            self.W0 = tf.random_uniform([self.ndims, 1], maxval=1)\n",
    "        elif W_init == 'gaussian':\n",
    "            self.W0 = tf.random_normal([self.ndims, 1],mean=0.0,stddev=0.1)\n",
    "        else:\n",
    "            print ('Unknown W_init ', W_init) \n",
    "        #self.graph = tf.Graph()\n",
    "        \n",
    "    def build_graph(self, learn_rate, Y_true, X):\n",
    "        \"\"\" build tensorflow training graph for logistic model.\n",
    "        Args:\n",
    "            learn_rate: learn rate for gradient descent\n",
    "            ......: append as many arguments as you want\n",
    "        \"\"\"\n",
    "        ###############################################################\n",
    "        # Fill your code in this function\n",
    "        ###############################################################\n",
    "        # Hint: self.W = tf.Variable(self.W0)\n",
    "        self.W = tf.Variable(self.W0)\n",
    "        self.lr = learn_rate\n",
    "        self.X_TF = X \n",
    "        self.y_TF = np.array([Y_true]).T.astype(int) \n",
    "        self.predictions = tf.sigmoid(tf.matmul(tf.cast(self.X_TF,tf.float32), self.W))\n",
    "        self.cost = tf.reduce_mean(tf.square(tf.subtract(tf.cast(self.y_TF,tf.float32), self.predictions)))\n",
    "        self.optimizer = tf.train.GradientDescentOptimizer(learning_rate=self.lr).minimize(self.cost)        \n",
    "\n",
    "        pass\n",
    "        \n",
    "    def fit(self, Y_true, X, max_iters, learn_rate):\n",
    "        \"\"\" train model with input dataset using gradient descent. \n",
    "        Args:\n",
    "            Y_true(numpy.ndarray): dataset labels with a dimension of (# of samples,1)\n",
    "            X(numpy.ndarray): input dataset with a dimension of (# of samples, ndims+1)\n",
    "            max_iters: maximal number of training iterations\n",
    "            ......: append as many arguments as you want\n",
    "        Returns:\n",
    "            (numpy.ndarray): sigmoid output from well trained logistic model, used for classification\n",
    "                             with a dimension of (# of samples, 1)\n",
    "        \"\"\"\n",
    "        ###############################################################\n",
    "        # Fill your code in this function\n",
    "        ###############################################################\n",
    "        def accuracy(Y_t, Y_p):\n",
    "            acc_vec = np.array([1 if Y_t[i] == Y_p[i] else 0 for i in range(len(Y_p))])\n",
    "            acc_val = np.mean(acc_vec)\n",
    "            return acc_vec, acc_val\n",
    "        \n",
    "        self.build_graph(learn_rate, Y_true, X)\n",
    "        init = tf.global_variables_initializer()\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(init)\n",
    "            Y = np.array([Y_true]).T.astype(int)    \n",
    "            for epoch in range(max_iters):\n",
    "                sess.run(self.optimizer)\n",
    "                if epoch % 200 == 0:\n",
    "                    pred = sess.run(self.predictions)\n",
    "                    self.classify = np.array([1  if pred[i]>= 0.5 else 0 for i in range(len(pred))])\n",
    "                    acc_vec, acc_val = accuracy(Y, self.classify)\n",
    "                    cost = sess.run(self.cost)\n",
    "                    \n",
    "                    print(epoch, '..', cost,acc_val)\n",
    "                if epoch+1 == max_iters:\n",
    "                    pred = sess.run(self.predictions)\n",
    "                    self.classify = np.array([1  if pred[i]>= 0.5 else 0 for i in range(len(pred))])\n",
    "                    acc_vec, acc_val = accuracy(Y, self.classify)\n",
    "                    print(\"Final step accuracy:\", acc_val)\n",
    "                    return acc_vec\n",
    "                    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model =LogisticModel_TF(17,'zeros')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 .. 0.234381 0.775968992248\n",
      "200 .. 0.0644364 0.941085271318\n",
      "400 .. 0.0530346 0.947286821705\n",
      "600 .. 0.0480378 0.949612403101\n",
      "800 .. 0.0450788 0.949612403101\n",
      "1000 .. 0.0430762 0.951162790698\n",
      "1200 .. 0.0416142 0.951937984496\n",
      "1400 .. 0.0404927 0.951937984496\n",
      "1600 .. 0.0396014 0.951937984496\n",
      "1800 .. 0.0388741 0.951937984496\n",
      "Final step accuracy: 0.954263565891\n"
     ]
    }
   ],
   "source": [
    "acc_ve = model.fit(Y_true, X,2000, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
      " 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(acc_ve[10:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "645.0\n",
      "[ 0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "print(1290/2)\n",
    "print(Y_true[770:800])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [tensorflow]",
   "language": "python",
   "name": "Python [tensorflow]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
