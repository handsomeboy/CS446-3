{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Input and output helpers to load in data.\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "def read_dataset_tf(path_to_dataset_folder,index_filename):\n",
    "    \"\"\" Read dataset into numpy arrays with preprocessing included\n",
    "    Args:\n",
    "        path_to_dataset_folder(str): path to the folder containing samples and indexing.txt\n",
    "        index_filename(str): indexing.txt\n",
    "    Returns:\n",
    "        A(numpy.ndarray): sample feature matrix A = [[1, x1], \n",
    "                                                     [1, x2], \n",
    "                                                     [1, x3],\n",
    "                                                     .......] \n",
    "                                where xi is the 16-dimensional feature of each sample\n",
    "            \n",
    "        T(numpy.ndarray): class label vector T = [y1, y2, y3, ...] \n",
    "                             where yi is +1/-1, the label of each sample \n",
    "    \"\"\"\n",
    "    with open(path_to_dataset_folder+'/'+index_filename, 'r') as f:\n",
    "        label_sample_path = f.readlines()\n",
    "    T = np.array([max(0,float(label_sample_path[i].split(' ')[0])) for i in range(len(label_sample_path))])\n",
    "    sample_path = [label_sample_path[i].split(' ')[1].replace('\\n','') for i in range(len(label_sample_path))]\n",
    "    \n",
    "    A = []\n",
    "    for i in range(len(sample_path)):\n",
    "        with open(path_to_dataset_folder+'/'+sample_path[i], 'r') as f:\n",
    "            row_data = f.read().strip().split('  ')\n",
    "#             print(row_data)\n",
    "            A.append([1.  if i ==0 else float(row_data[i-1]) for i in range(len(row_data)+1)])\n",
    "    A = np.array(A)\n",
    "    \n",
    "        \n",
    "    \n",
    "    return A, T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, Y_true = read_dataset_tf('C:/Users/PIxel/CS446/mp3/data/trainset','indexing.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0. ...,  1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "print(Y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"logistic model class for binary classification.\"\"\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "class LogisticModel_TF(object):\n",
    "    \n",
    "    def __init__(self, ndims, W_init='zeros'):\n",
    "        \"\"\"Initialize a logistic model.\n",
    "\n",
    "        This function prepares an initialized logistic model.\n",
    "        It will initialize the weight vector, self.W, based on the method\n",
    "        specified in W_init.\n",
    "\n",
    "        We assume that the FIRST index of Weight is the bias term, \n",
    "            Weight = [Bias, W1, W2, W3, ...] \n",
    "            where Wi correspnds to each feature dimension\n",
    "\n",
    "        W_init needs to support:\n",
    "          'zeros': initialize self.W with all zeros.\n",
    "          'ones': initialze self.W with all ones.\n",
    "          'uniform': initialize self.W with uniform random number between [0,1)\n",
    "          'gaussian': initialize self.W with gaussion distribution (0, 0.1)\n",
    "\n",
    "        Args:\n",
    "            ndims(int): feature dimension\n",
    "            W_init(str): types of initialization.\n",
    "        \"\"\"\n",
    "        self.ndims = ndims\n",
    "        self.W_init = W_init\n",
    "        self.W0 = None\n",
    "        ###############################################################\n",
    "        # Fill your code below\n",
    "        ###############################################################\n",
    "        if W_init == 'zeros':\n",
    "            # Hint: self.W0 = tf.zeros([self.ndims+1,1])\n",
    "            self.W0 = tf.zeros([self.ndims+1, 1])\n",
    "        elif W_init == 'ones':\n",
    "            self.W0 = tf.ones([self.ndims+1, 1])\n",
    "        elif W_init == 'uniform':\n",
    "            self.W0 = tf.random_uniform([self.ndims+1, 1], maxval=1)\n",
    "        elif W_init == 'gaussian':\n",
    "            self.W0 = tf.random_normal([self.ndims+1, 1],mean=0.0,stddev=0.1)\n",
    "        else:\n",
    "            print ('Unknown W_init ', W_init) \n",
    "        #self.graph = tf.Graph()\n",
    "        \n",
    "    def build_graph(self, learn_rate):\n",
    "        \"\"\" build tensorflow training graph for logistic model.\n",
    "        Args:\n",
    "            learn_rate: learn rate for gradient descent\n",
    "            ......: append as many arguments as you want\n",
    "        \"\"\"\n",
    "        ###############################################################\n",
    "        # Fill your code in this function\n",
    "        ###############################################################\n",
    "        # Hint: self.W = tf.Variable(self.W0)\n",
    "        self.W = tf.Variable(self.W0)\n",
    "        self.lr = learn_rate\n",
    "#         self.X_TF = X \n",
    "#         self.y_TF = np.array([Y_true]).T.astype(int) \n",
    "        self.X_TF = tf.placeholder(tf.float32, [None, self.ndims+1])\n",
    "        self.y_TF = tf.placeholder(tf.int32, [None, 1])\n",
    "        self.predictions = tf.sigmoid(tf.matmul(tf.cast(self.X_TF,tf.float32), self.W))\n",
    "        self.cost = tf.reduce_mean(tf.square(tf.subtract(tf.cast(self.y_TF,tf.float32), self.predictions)))\n",
    "        self.optimizer = tf.train.GradientDescentOptimizer(learning_rate=self.lr).minimize(self.cost)        \n",
    "\n",
    "        pass\n",
    "        \n",
    "    def fit(self, Y_true, X, max_iters):\n",
    "        \"\"\" train model with input dataset using gradient descent. \n",
    "        Args:\n",
    "            Y_true(numpy.ndarray): dataset labels with a dimension of (# of samples,1)\n",
    "            X(numpy.ndarray): input dataset with a dimension of (# of samples, ndims+1)\n",
    "            max_iters: maximal number of training iterations\n",
    "            ......: append as many arguments as you want\n",
    "        Returns:\n",
    "            (numpy.ndarray): sigmoid output from well trained logistic model, used for classification\n",
    "                             with a dimension of (# of samples, 1)\n",
    "        \"\"\"\n",
    "        ###############################################################\n",
    "        # Fill your code in this function\n",
    "        ###############################################################\n",
    "        def accuracy(Y_t, Y_p):\n",
    "            acc_vec = np.array([1 if Y_t[i] == Y_p[i] else 0 for i in range(len(Y_p))])\n",
    "            acc_val = np.mean(acc_vec)\n",
    "            return acc_vec, acc_val\n",
    "        \n",
    "#         self.build_graph(learn_rate, Y_true, X)\n",
    "        init = tf.global_variables_initializer()\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(init)\n",
    "            Y = np.array([Y_true]).T.astype(int)    \n",
    "            for epoch in range(max_iters):\n",
    "                sess.run(self.optimizer, feed_dict={self.X_TF: X, self.y_TF: Y})\n",
    "                if epoch % 100 == 0:\n",
    "                    pred = sess.run(self.predictions, feed_dict={self.X_TF: X})\n",
    "                    self.classify = np.array([1  if pred[i]>= 0.5 else 0 for i in range(len(pred))])\n",
    "                    acc_vec, acc_val = accuracy(Y, self.classify)\n",
    "                    cost = sess.run(self.cost, feed_dict={self.X_TF: X, self.y_TF: Y})\n",
    "                    \n",
    "                    print(epoch, '..', cost,acc_val)\n",
    "                if epoch+1 == max_iters:\n",
    "                    pred = sess.run(self.predictions, feed_dict={self.X_TF: X})\n",
    "                    self.classify = np.array([1  if pred[i]>= 0.5 else 0 for i in range(len(pred))])\n",
    "                    acc_vec, acc_val = accuracy(Y, self.classify)\n",
    "                    print(\"Final step accuracy:\", acc_val)\n",
    "                    return pred\n",
    "                    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model =LogisticModel_TF(16,'ones')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.build_graph(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 .. 0.571242 0.414728682171\n",
      "100 .. 0.56734 0.416279069767\n",
      "200 .. 0.562977 0.42015503876\n",
      "300 .. 0.558415 0.42480620155\n",
      "400 .. 0.553953 0.429457364341\n",
      "500 .. 0.549821 0.434108527132\n",
      "600 .. 0.546129 0.437209302326\n",
      "700 .. 0.542892 0.443410852713\n",
      "800 .. 0.540078 0.448062015504\n",
      "900 .. 0.537632 0.448062015504\n",
      "1000 .. 0.535493 0.450387596899\n",
      "1100 .. 0.533601 0.45503875969\n",
      "1200 .. 0.531901 0.45503875969\n",
      "1300 .. 0.530346 0.458139534884\n",
      "1400 .. 0.528893 0.459689922481\n",
      "1500 .. 0.527506 0.462015503876\n",
      "1600 .. 0.526153 0.463565891473\n",
      "1700 .. 0.524801 0.464341085271\n",
      "1800 .. 0.523422 0.465891472868\n",
      "1900 .. 0.521989 0.466666666667\n",
      "2000 .. 0.520475 0.466666666667\n",
      "2100 .. 0.518858 0.46511627907\n",
      "2200 .. 0.517121 0.46511627907\n",
      "2300 .. 0.515251 0.462015503876\n",
      "2400 .. 0.513245 0.467441860465\n",
      "2500 .. 0.511101 0.468217054264\n",
      "2600 .. 0.508823 0.468217054264\n",
      "2700 .. 0.506409 0.46976744186\n",
      "2800 .. 0.50385 0.468992248062\n",
      "2900 .. 0.501119 0.471317829457\n",
      "3000 .. 0.49817 0.477519379845\n",
      "3100 .. 0.494924 0.480620155039\n",
      "3200 .. 0.491263 0.481395348837\n",
      "3300 .. 0.487006 0.482945736434\n",
      "3400 .. 0.48188 0.485271317829\n",
      "3500 .. 0.475465 0.492248062016\n",
      "3600 .. 0.467114 0.496124031008\n",
      "3700 .. 0.455871 0.5\n",
      "3800 .. 0.440567 0.508527131783\n",
      "3900 .. 0.420482 0.523255813953\n",
      "4000 .. 0.3966 0.547286821705\n",
      "4100 .. 0.371686 0.577519379845\n",
      "4200 .. 0.348277 0.606201550388\n",
      "4300 .. 0.327298 0.632558139535\n",
      "4400 .. 0.30844 0.658139534884\n",
      "4500 .. 0.290643 0.678294573643\n",
      "4600 .. 0.272177 0.691472868217\n",
      "4700 .. 0.250458 0.709302325581\n",
      "4800 .. 0.220259 0.732558139535\n",
      "4900 .. 0.167449 0.76511627907\n",
      "5000 .. 0.122949 0.834108527132\n",
      "5100 .. 0.118545 0.838759689922\n",
      "5200 .. 0.115734 0.841085271318\n",
      "5300 .. 0.113171 0.846511627907\n",
      "5400 .. 0.110798 0.849612403101\n",
      "5500 .. 0.108589 0.852713178295\n",
      "5600 .. 0.106521 0.855813953488\n",
      "5700 .. 0.104578 0.858914728682\n",
      "5800 .. 0.102745 0.861240310078\n",
      "5900 .. 0.101011 0.861240310078\n",
      "6000 .. 0.0993654 0.861240310078\n",
      "6100 .. 0.0977994 0.86511627907\n",
      "6200 .. 0.0963059 0.866666666667\n",
      "6300 .. 0.0948785 0.870542635659\n",
      "6400 .. 0.0935114 0.871317829457\n",
      "6500 .. 0.0921997 0.87519379845\n",
      "6600 .. 0.090939 0.876744186047\n",
      "6700 .. 0.0897253 0.878294573643\n",
      "6800 .. 0.0885553 0.87984496124\n",
      "6900 .. 0.0874256 0.881395348837\n",
      "7000 .. 0.0863336 0.883720930233\n",
      "7100 .. 0.0852768 0.883720930233\n",
      "7200 .. 0.0842529 0.884496124031\n",
      "7300 .. 0.0832599 0.884496124031\n",
      "7400 .. 0.082296 0.887596899225\n",
      "7500 .. 0.0813597 0.88992248062\n",
      "7600 .. 0.0804494 0.88992248062\n",
      "7700 .. 0.079564 0.88992248062\n",
      "7800 .. 0.0787022 0.88992248062\n",
      "7900 .. 0.077863 0.892248062016\n",
      "8000 .. 0.0770456 0.893023255814\n",
      "8100 .. 0.076249 0.893798449612\n",
      "8200 .. 0.0754726 0.895348837209\n",
      "8300 .. 0.0747156 0.897674418605\n",
      "8400 .. 0.0739774 0.897674418605\n",
      "8500 .. 0.0732576 0.898449612403\n",
      "8600 .. 0.0725555 0.9\n",
      "8700 .. 0.0718707 0.902325581395\n",
      "8800 .. 0.0712028 0.902325581395\n",
      "8900 .. 0.0705513 0.902325581395\n",
      "9000 .. 0.0699159 0.905426356589\n",
      "9100 .. 0.0692961 0.906201550388\n",
      "9200 .. 0.0686916 0.906976744186\n",
      "9300 .. 0.0681019 0.908527131783\n",
      "9400 .. 0.0675268 0.909302325581\n",
      "9500 .. 0.0669659 0.910852713178\n",
      "9600 .. 0.0664189 0.912403100775\n",
      "9700 .. 0.0658854 0.913178294574\n",
      "9800 .. 0.065365 0.914728682171\n",
      "9900 .. 0.0648574 0.915503875969\n",
      "Final step accuracy: 0.916279069767\n"
     ]
    }
   ],
   "source": [
    "acc_ve = model.fit(Y_true, X,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.18065841e-01]\n",
      " [  3.92793864e-02]\n",
      " [  1.88404560e-01]\n",
      " [  2.57774610e-02]\n",
      " [  2.34458208e-01]\n",
      " [  5.01027480e-02]\n",
      " [  7.75374472e-02]\n",
      " [  1.52949896e-02]\n",
      " [  9.01941024e-03]\n",
      " [  3.52382064e-02]\n",
      " [  6.32262463e-03]\n",
      " [  1.17558241e-03]\n",
      " [  1.38561660e-02]\n",
      " [  5.98012693e-02]\n",
      " [  7.99618720e-04]\n",
      " [  4.76046326e-03]\n",
      " [  6.84783212e-04]\n",
      " [  3.76665555e-02]\n",
      " [  2.02227547e-03]\n",
      " [  1.10060321e-02]\n",
      " [  6.24356270e-02]\n",
      " [  3.66048096e-03]\n",
      " [  8.88417591e-04]\n",
      " [  6.36089360e-04]\n",
      " [  4.26505413e-03]\n",
      " [  1.14038102e-02]\n",
      " [  2.51440536e-02]\n",
      " [  2.60696840e-02]\n",
      " [  4.33882289e-02]\n",
      " [  7.62630478e-02]\n",
      " [  8.08231592e-01]\n",
      " [  3.56773697e-02]\n",
      " [  7.56500568e-03]\n",
      " [  1.47413025e-02]\n",
      " [  2.05336809e-01]\n",
      " [  5.66402934e-02]\n",
      " [  9.20932647e-03]\n",
      " [  5.34996875e-02]\n",
      " [  1.43743515e-01]\n",
      " [  7.44304806e-03]]\n"
     ]
    }
   ],
   "source": [
    "print(acc_ve[10:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "645.0\n",
      "[ 0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "print(1290/2)\n",
    "print(Y_true[770:800])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [tensorflow]",
   "language": "python",
   "name": "Python [tensorflow]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
