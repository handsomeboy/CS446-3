{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Input and output helpers to load in data.\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "def read_dataset(path_to_dataset_folder,index_filename):\n",
    "    \"\"\" Read dataset into numpy arrays with preprocessing included\n",
    "    Args:\n",
    "        path_to_dataset_folder(str): path to the folder containing samples and indexing.txt\n",
    "        index_filename(str): indexing.txt\n",
    "    Returns:\n",
    "        A(numpy.ndarray): sample feature matrix A = [[1, x1], \n",
    "                                                     [1, x2], \n",
    "                                                     [1, x3],\n",
    "                                                     .......] \n",
    "                                where xi is the 16-dimensional feature of each sample\n",
    "            \n",
    "        T(numpy.ndarray): class label vector T = [y1, y2, y3, ...] \n",
    "                             where yi is +1/-1, the label of each sample \n",
    "    \"\"\"\n",
    "    with open(path_to_dataset_folder+'/'+index_filename, 'r') as f:\n",
    "        label_sample_path = f.readlines()\n",
    "    T = np.array([int(label_sample_path[i].split(' ')[0]) for i in range(len(label_sample_path))])\n",
    "    sample_path = [label_sample_path[i].split(' ')[1].replace('\\n','') for i in range(len(label_sample_path))]\n",
    "    \n",
    "    A = []\n",
    "    for i in range(len(sample_path)):\n",
    "        with open(path_to_dataset_folder+'/'+sample_path[i], 'r') as f:\n",
    "            row_data = f.read().strip().split('  ')\n",
    "            A.append([1.  if i ==0 else float(row_data[i-1]) for i in range(len(row_data)+1)])\n",
    "    A = np.array(A)\n",
    "    \n",
    "        \n",
    "    \n",
    "    return A, T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, Y_true = read_dataset('C:/Users/PIxel/CS446/mp3/data/trainset','indexing.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1290 17 1290\n"
     ]
    }
   ],
   "source": [
    "print(len(X), len(X[0]), (len(Y_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"logistic model class for binary classification.\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class LogisticModel(object):\n",
    "    \n",
    "    def __init__(self, ndims, W_init='zeros'):\n",
    "        \"\"\"Initialize a logistic model.\n",
    "\n",
    "        This function prepares an initialized logistic model.\n",
    "        It will initialize the weight vector, self.W, based on the method\n",
    "        specified in W_init.\n",
    "\n",
    "        We assume that the FIRST index of W is the bias term, \n",
    "            self.W = [Bias, W1, W2, W3, ...] \n",
    "            where Wi correspnds to each feature dimension\n",
    "\n",
    "        W_init needs to support:\n",
    "          'zeros': initialize self.W with all zeros.\n",
    "          'ones': initialze self.W with all ones.\n",
    "          'uniform': initialize self.W with uniform random number between [0,1)\n",
    "          'gaussian': initialize self.W with gaussion distribution (0, 0.1)\n",
    "\n",
    "        Args:\n",
    "            ndims(int): feature dimension\n",
    "            W_init(str): types of initialization.\n",
    "        \"\"\"\n",
    "        self.ndims = ndims\n",
    "        self.W_init = W_init\n",
    "        self.W = None\n",
    "        if W_init == 'zeros':\n",
    "            self.W = np.zeros(self.ndims+1)    \n",
    "        elif W_init == 'ones':\n",
    "            self.W = np.ones(self.ndims+1)\n",
    "        elif W_init == 'uniform':\n",
    "            self.W = np.random.uniform(0,1,self.ndims+1)\n",
    "        elif W_init == 'gaussian':\n",
    "            self.W = np.radnom.normal(0,0.1, self.ndims+1)\n",
    "        else:\n",
    "            print ('Unknown W_init ', W_init) \n",
    "        self.X = None\n",
    "        \n",
    "    def save_model(self, weight_file):\n",
    "        \"\"\" Save well-trained weight into a binary file.\n",
    "        Args:\n",
    "            weight_file(str): binary file to save into.\n",
    "        \"\"\"\n",
    "        self.W.astype('float32').tofile(weight_file)\n",
    "        print ('model saved to', weight_file)\n",
    "\n",
    "    def load_model(self, weight_file):\n",
    "        \"\"\" Load pretrained weghit from a binary file.\n",
    "        Args:\n",
    "            weight_file(str): binary file to load from.\n",
    "        \"\"\"\n",
    "        self.W = np.fromfile(weight_file, dtype=np.float32)\n",
    "        print ('model loaded from', weight_file)\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\" Forward operation for logistic models.\n",
    "            Performs the forward operation, and return probability score (sigmoid).\n",
    "        Args:\n",
    "            X(numpy.ndarray): input dataset with a dimension of (# of samples, ndims+1)\n",
    "        Returns:\n",
    "            (numpy.ndarray): probability score of (label == +1) for each sample \n",
    "                             with a dimension of (# of samples,)\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        f = 1./ ( 1. + np.exp(-np.matmul(self.X,self.W)))\n",
    "        return f\n",
    "\n",
    "    def backward(self, Y_true, X):\n",
    "        \"\"\" Backward operation for logistic models. \n",
    "            Compute gradient according to the probability loss on lecture slides\n",
    "        Args:\n",
    "            X(numpy.ndarray): input dataset with a dimension of (# of samples, ndims+1)\n",
    "            Y_true(numpy.ndarray): dataset labels with a dimension of (# of samples,)\n",
    "        Returns:\n",
    "            (numpy.ndarray): gradients of self.W\n",
    "        \"\"\"\n",
    "        ###############################################################\n",
    "        # Fill your code in this function\n",
    "        \n",
    "        Y_true.reshape((-1,1))\n",
    "        \n",
    "        D1 = -np.transpose(np.multiply(Y_true,np.transpose(X)))    \n",
    "        D2 = np.exp(-np.multiply(Y_true,np.matmul(self.X,self.W)))\n",
    "        N = np.add(1,D2)\n",
    "        DN = np.divide(D2, N)       \n",
    "        total_grad = np.matmul(DN, D1)\n",
    "        \n",
    "        return total_grad\n",
    "\n",
    "    def classify(self, X):\n",
    "        \"\"\" Performs binary classification on input dataset.\n",
    "        Args:\n",
    "            X(numpy.ndarray): input dataset with a dimension of (# of samples, ndims+1)\n",
    "        Returns:\n",
    "            (numpy.ndarray): predicted label = +1/-1 for each sample\n",
    "                             with a dimension of (# of samples,)\n",
    "        \"\"\"\n",
    "        ###############################################################\n",
    "        # Fill your code in this function\n",
    "        ###############################################################\n",
    "        f = self.forward(X)\n",
    "        \n",
    "        return np.array([1  if f[i] >= 0.5 else -1 for i in range(len(f))])\n",
    "    \n",
    "    def fit(self, Y_true, X, learn_rate, max_iters):\n",
    "        \"\"\" train model with input dataset using gradient descent. \n",
    "        Args:\n",
    "            Y_true(numpy.ndarray): dataset labels with a dimension of (# of samples,)\n",
    "            X(numpy.ndarray): input dataset with a dimension of (# of samples, ndims+1)\n",
    "            learn_rate: learning rate for gradient descent\n",
    "            max_iters: maximal number of iterations\n",
    "            ......: append as many arguments as you want\n",
    "        \"\"\"\n",
    "        \n",
    "        def accuracy(Y_t, Y_p):\n",
    "            return np.sum([1 if Y_t[i] == Y_p[i] else 0 for i in range(len(Y_p))])/len(Y_p)\n",
    "            \n",
    "        for i in range(max_iters):\n",
    "            total_grad = self.backward(Y_true, X)\n",
    "            self.W -= learn_rate * total_grad\n",
    "            \n",
    "            if i% 100 == 0:\n",
    "                Y_n = self.classify(X)\n",
    "                acc = accuracy(Y_true, Y_n)\n",
    "                print(acc)\n",
    "            \n",
    "        return self.W\n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = LogisticModel(16, 'ones')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99999373  0.99997404  0.99997296  0.99998708  0.99992228  0.99999874\n",
      "  0.9999981   0.99998111  0.99995259] 1290\n"
     ]
    }
   ],
   "source": [
    "f = model.forward(X)\n",
    "print(f[1:10], len(f))\n",
    "c = model.classify(X)\n",
    "# print(c[220:400], len(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_grad1 = model.backward(Y_true, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ..., 1 1 1]\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "print(c)\n",
    "print(len(total_grad1))#, len(total_grad1[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.582170542636\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.41631785,  1.0104817 ,  1.61936464, -3.62188704, -1.52157379,\n",
       "        0.79156122, -0.66503333,  1.96390844,  2.20266528,  2.18294404,\n",
       "        0.03468568, -0.20858415,  0.73128432,  0.30091493,  0.96691144,\n",
       "        0.63954187,  0.91082492])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Y_true, X, 0.001,20)\n",
    "#print(np.sum([1 if Y_true[i]==-1 else 0 for i in range(len(Y_true))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1 -1 -1 -1 -1]\n",
      "[-1 -1 -1 -1 -1]\n"
     ]
    }
   ],
   "source": [
    "c = model.classify(X)\n",
    "print(c[10:15])\n",
    "print(Y_true[10:15])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved to trained_weights.np\n"
     ]
    }
   ],
   "source": [
    "model.save_model('trained_weights.np')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded from trained_weights.np\n"
     ]
    }
   ],
   "source": [
    "model.load_model('trained_weights.np')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1 -1 -1 -1 -1]\n",
      "[-1 -1 -1 -1 -1]\n"
     ]
    }
   ],
   "source": [
    "c = model.classify(X)\n",
    "print(c[10:15])\n",
    "print(Y_true[10:15])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.46911895, -0.0405732 ,  0.44669679, -2.33442211, -0.77778155,\n",
       "       -0.52750027, -1.32548511,  2.19791985,  2.64580703,  1.19006515,\n",
       "       -1.24726415, -3.28505969, -0.43239495, -0.62762898,  2.59026861,\n",
       "       -2.24624372, -0.2439252 ], dtype=float32)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [tensorflow]",
   "language": "python",
   "name": "Python [tensorflow]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
